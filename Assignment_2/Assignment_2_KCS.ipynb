{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2:\n",
    "### Visualizing High Dimensional Data\n",
    "#### Kendall Stauffer (U0688677)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing important libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1:\n",
    " - Implement PCA as a function and provide a commented version of it. Feel free to compute eigenvectors, eigenvalues etc. using numpy or other api functionality.\n",
    " - Plot (with a scatter plot) the iris dataset using your PCA implementation. Color each of the species differently. On a separate plot provide a scatter plot of the language api (sklearn) PCA for comparison.\n",
    " - Run K-Means on these results with k=2 and plot the results color according to cluster\n",
    " - Now create an alternate PCA function where you do not center the data. Using a scatter plot, show the results. Again, color each of the species differently.\n",
    " - What is the effect of neglecting to center the data? What type of data would not work well for PCA and why?\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    " def compute_PCA(data, scale_data = True):\n",
    "        \"\"\"\n",
    "        Params data: A dataframe or array that contains the data for pca.\n",
    "        Params scale_data: if set to True, data will be scaled with mean center scaling.\n",
    "        Return: Returns a python dictionary that contains the calculated percent variance and decomposed values.\n",
    "        \"\"\"\n",
    "        # if scaled data = True do mean center scaling\n",
    "        if scale_data:\n",
    "            # import mean center scaling\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            # initialize the scaler\n",
    "            scaler = StandardScaler()\n",
    "            # fit the data to scaler\n",
    "            scaler.fit(data)\n",
    "            # scale the data\n",
    "            temp = scaler.transform(data)\n",
    "        else:\n",
    "            # don't scale data\n",
    "            temp = data\n",
    "        # calculate covariance matrix\n",
    "        cov = np.cov(temp.transpose())\n",
    "        # calculate eigen vector and values\n",
    "        values, vectors = np.linalg.eig(cov)\n",
    "        # sorting eigen values and vectors by highest eigen value\n",
    "           \n",
    "        # calculate % variance for every value\n",
    "        temp_vals = values.tolist()\n",
    "        percent_variance = [np.round((temp_vals[i]/sum(temp_vals))*100, 2) for i in range(len(temp_vals))]\n",
    "        \n",
    "        # taking the dot product of scaled data by eigenvetors transposed\n",
    "        temp_pca = temp.dot(vectors.transpose())\n",
    "        # making columnames\n",
    "        col_names = [f\"PC{i}\" for i in range(temp_pca.shape[1])]\n",
    "        # making a pandas dataframe\n",
    "        temp_pca = pd.DataFrame(temp_pca, columns = col_names)\n",
    "        # returning as a python dictionary that contains the percent variation and decomposed data.\n",
    "        temp_final = {'percent_variance': percent_variance,\n",
    "                     'pca': temp_pca}\n",
    "        return temp_final       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "  classes  \n",
       "0  setosa  \n",
       "1  setosa  \n",
       "2  setosa  \n",
       "3  setosa  \n",
       "4  setosa  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing data\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
    "df['classes'] = iris.target\n",
    "df.classes = np.where(df.classes ==  0, iris.target_names[0], df.classes)\n",
    "df.classes = np.where(df.classes ==  1, iris.target_names[1], df.classes)\n",
    "df.classes = np.where(df.classes ==  2, iris.target_names[2], df.classes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running my own pca function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72.96244541329985, 22.850761786701778, 3.668921889282875, 0.5178709107154802]\n",
      "       PC_0      PC_1      PC_2      PC_3\n",
      "0 -0.233230 -0.863303  0.316056 -2.115802\n",
      "1  0.074899  0.264668  0.203591 -2.175638\n",
      "2 -0.184237 -0.109029  0.043582 -2.379393\n",
      "3 -0.242289  0.163927 -0.004951 -2.360324\n",
      "4 -0.383247 -1.043206  0.240091 -2.199654\n"
     ]
    }
   ],
   "source": [
    "kcs_pca_scaled = compute_PCA(df.iloc[:,:-1])\n",
    "print(kcs_pca_scaled['percent_variance'])\n",
    "print(kcs_pca_scaled['pca'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running sklearn pca function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72962445 0.22850762 0.03668922 0.00517871]\n",
      "        PC0       PC1       PC2       PC3\n",
      "0 -2.264703  0.480027 -0.127706 -0.024168\n",
      "1 -2.080961 -0.674134 -0.234609 -0.103007\n",
      "2 -2.364229 -0.341908  0.044201 -0.028377\n",
      "3 -2.299384 -0.597395  0.091290  0.065956\n",
      "4 -2.389842  0.646835  0.015738  0.035923\n"
     ]
    }
   ],
   "source": [
    "pca_sklearn = PCA()\n",
    "df_scaled = StandardScaler().fit_transform(df.iloc[:,:-1])\n",
    "pca_sklearn.fit(df_scaled)\n",
    "print(pca_sklearn.explained_variance_ratio_)\n",
    "pca_sklearn_data = pd.DataFrame(pca_sklearn.transform(df_scaled), columns = ['PC0', 'PC1', 'PC2', 'PC3'])\n",
    "print(pca_sklearn_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running my own unscaled pca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.46187232017272, 5.306648311706787, 1.7102609807929738, 0.5212183873275305]\n",
      "       PC_0      PC_1      PC_2      PC_3\n",
      "0 -1.206733 -2.213499  4.986587  3.006354\n",
      "1 -0.950716 -1.831514  4.728567  2.896956\n",
      "2 -1.096108 -2.020433  4.584283  2.785811\n",
      "3 -1.182994 -1.819382  4.496526  2.851600\n",
      "4 -1.308531 -2.278063  4.918257  2.978073\n"
     ]
    }
   ],
   "source": [
    "kcs_pca_scaled = compute_PCA(df.iloc[:,:-1].values, scale_data=False)\n",
    "print(kcs_pca_scaled['percent_variance'])\n",
    "print(kcs_pca_scaled['pca'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92461872 0.05306648 0.01710261 0.00521218]\n",
      "        PC0       PC1       PC2       PC3\n",
      "0 -2.684126  0.319397 -0.027915 -0.002262\n",
      "1 -2.714142 -0.177001 -0.210464 -0.099027\n",
      "2 -2.888991 -0.144949  0.017900 -0.019968\n",
      "3 -2.745343 -0.318299  0.031559  0.075576\n",
      "4 -2.728717  0.326755  0.090079  0.061259\n"
     ]
    }
   ],
   "source": [
    "pca_sklearn = PCA()\n",
    "df_scaled = df.iloc[:,:-1]\n",
    "pca_sklearn.fit(df_scaled)\n",
    "print(pca_sklearn.explained_variance_ratio_)\n",
    "pca_sklearn_data = pd.DataFrame(pca_sklearn.transform(df_scaled), columns = ['PC0', 'PC1', 'PC2', 'PC3'])\n",
    "print(pca_sklearn_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
